{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nouryahiaaaa/DEPI-exercises-assigns-/blob/main/Untitled1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "kFJ_56yTmDUu",
        "outputId": "318d86a6-52f0-4d19-9983-9e02a59dcd84"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-58af2db1-8777-4114-8749-39a1d76c198f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-58af2db1-8777-4114-8749-39a1d76c198f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "Dataset URL: https://www.kaggle.com/datasets/fernando2rad/brain-tumor-mri-images-44c\n",
            "License(s): Community Data License Agreement - Sharing - Version 1.0\n",
            "Dataset split completed.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets download -d fernando2rad/brain-tumor-mri-images-44c\n",
        "\n",
        "!unzip -q brain-tumor-mri-images-44c.zip -d brain_tumor_data\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data_dir = 'brain_tumor_data'\n",
        "classes = os.listdir(data_dir)\n",
        "\n",
        "os.makedirs('brain_tumor_split/train', exist_ok=True)\n",
        "os.makedirs('brain_tumor_split/test', exist_ok=True)\n",
        "\n",
        "for cls in classes:\n",
        "    cls_path = os.path.join(data_dir, cls)\n",
        "    images = os.listdir(cls_path)\n",
        "\n",
        "    train_imgs, test_imgs = train_test_split(images, test_size=0.2, random_state=42)\n",
        "\n",
        "    os.makedirs(f'brain_tumor_split/train/{cls}', exist_ok=True)\n",
        "    os.makedirs(f'brain_tumor_split/test/{cls}', exist_ok=True)\n",
        "\n",
        "    for img in train_imgs:\n",
        "        shutil.copy(os.path.join(cls_path, img), f'brain_tumor_split/train/{cls}/{img}')\n",
        "    for img in test_imgs:\n",
        "        shutil.copy(os.path.join(cls_path, img), f'brain_tumor_split/test/{cls}/{img}')\n",
        "\n",
        "print(\"Dataset split completed.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dS7iWOea5Oec"
      },
      "source": [
        "Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sn4hbmEi5QIE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkyamCXE5Rqj"
      },
      "source": [
        "Choosing device (check if GPU is avb else use CPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F517DDDJ5aHw",
        "outputId": "b92a28e5-630a-47e2-ea88-bdd979e4b6ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGaKrO8y65-Z"
      },
      "source": [
        "Setting DS directory from train and test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k1A84Mdj7D_4"
      },
      "outputs": [],
      "source": [
        "data_dir = \"./brain_tumor_split\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKsKXwQQ7HRy"
      },
      "source": [
        "Image preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WdW938SY7J2Q"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.Grayscale(num_output_channels=3),  # converting 1(grayscale) into 3(RGB)\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        " #normalizing to make all pixel values to be centered around 0 with a standard deviation of 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5rF7hf69CFW"
      },
      "source": [
        "Loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXO1zUju9EUb",
        "outputId": "6a2376db-99b7-4b62-83d2-0bf03581cf72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Astrocitoma T1', 'Astrocitoma T1C+', 'Astrocitoma T2', 'Carcinoma T1', 'Carcinoma T1C+', 'Carcinoma T2', 'Ependimoma T1', 'Ependimoma T1C+', 'Ependimoma T2', 'Ganglioglioma T1', 'Ganglioglioma T1C+', 'Ganglioglioma T2', 'Germinoma T1', 'Germinoma T1C+', 'Germinoma T2', 'Glioblastoma T1', 'Glioblastoma T1C+', 'Glioblastoma T2', 'Granuloma T1', 'Granuloma T1C+', 'Granuloma T2', 'Meduloblastoma T1', 'Meduloblastoma T1C+', 'Meduloblastoma T2', 'Meningioma T1', 'Meningioma T1C+', 'Meningioma T2', 'Neurocitoma T1', 'Neurocitoma T1C+', 'Neurocitoma T2', 'Oligodendroglioma T1', 'Oligodendroglioma T1C+', 'Oligodendroglioma T2', 'Papiloma T1', 'Papiloma T1C+', 'Papiloma T2', 'Schwannoma T1', 'Schwannoma T1C+', 'Schwannoma T2', 'Tuberculoma T1', 'Tuberculoma T1C+', 'Tuberculoma T2', '_NORMAL T1', '_NORMAL T2']\n"
          ]
        }
      ],
      "source": [
        "train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform)\n",
        "test_dataset = datasets.ImageFolder(os.path.join(data_dir, 'test'), transform=transform)\n",
        "#data loaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "class_names = train_dataset.classes\n",
        "print(\"Classes:\", class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RimA57qT9ost"
      },
      "source": [
        "PreTrained model (DenseNet-121 & DenseNet-169)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "E3PVbW__9vLW"
      },
      "outputs": [],
      "source": [
        "def create_densenet_model(variant='densenet121', num_classes=2):\n",
        "    if variant == 'densenet121':\n",
        "        model = models.densenet121(pretrained=True)\n",
        "    elif variant == 'densenet169':\n",
        "        model = models.densenet169(pretrained=True)\n",
        "    else:\n",
        "        raise ValueError(\"Only 'densenet121' and 'densenet169' are supported.\")\n",
        "\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = False\n",
        "    num_classes = len(train_dataset.classes)\n",
        "    num_ftrs = model.classifier.in_features\n",
        "    model.classifier = nn.Sequential(\n",
        "        nn.Linear(num_ftrs, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.4),\n",
        "        nn.Linear(512, num_classes)\n",
        "    )\n",
        "    return model.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmW_F26y_PZr"
      },
      "source": [
        "Training the model with 5 epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "GGW-9yXw_Sdy"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_loader, val_loader=None, epochs=5):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.classifier.parameters(), lr=0.001)\n",
        "\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "        print(f\"Epoch [{epoch+1}/{epochs}], Train Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "        # Validation\n",
        "        if val_loader is not None:\n",
        "            model.eval()\n",
        "            val_loss = 0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    val_loss += loss.item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "            avg_val_loss = val_loss / len(val_loader)\n",
        "            val_acc = 100 * correct / total\n",
        "            val_losses.append(avg_val_loss)\n",
        "            val_accuracies.append(val_acc)\n",
        "\n",
        "            print(f\"Validation Loss: {avg_val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
        "\n",
        "    return model, train_losses, val_losses, val_accuracies"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQoDqXB3ALYz"
      },
      "source": [
        "Models evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aY7gkpnzAO67"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images = images.to(device)\n",
        "            outputs = model(images)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            y_true.extend(labels.numpy())\n",
        "            y_pred.extend(preds.cpu().numpy())\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    print(f\"\\nAccuracy: {acc * 100:.2f}%\")\n",
        "\n",
        "    print(classification_report(y_true, y_pred, target_names=class_names))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "# Assuming `train_dataset` is your dataset\n",
        "train_size = int(0.8 * len(train_dataset))  # 80% training\n",
        "val_size = len(train_dataset) - train_size  # 20% validation\n",
        "\n",
        "train_subset, val_subset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "# Now create loaders\n",
        "train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_subset, batch_size=32)\n"
      ],
      "metadata": {
        "id": "onDg1oZNWeoK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRAG-Va1Blkf"
      },
      "source": [
        "Model DenseNet-121 callings for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkZtbXcOBsGF",
        "outputId": "a7dff1ef-80e9-42f2-fd44-e51571c4e508"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training DenseNet-121: \n",
            "Epoch [1/10], Train Loss: 2.9872\n",
            "Validation Loss: 2.2813, Accuracy: 39.55%\n",
            "Epoch [2/10], Train Loss: 2.0541\n",
            "Validation Loss: 1.7893, Accuracy: 48.67%\n",
            "Epoch [3/10], Train Loss: 1.6848\n",
            "Validation Loss: 1.5019, Accuracy: 56.24%\n",
            "Epoch [4/10], Train Loss: 1.4346\n",
            "Validation Loss: 1.4087, Accuracy: 58.91%\n",
            "Epoch [5/10], Train Loss: 1.2970\n",
            "Validation Loss: 1.2623, Accuracy: 63.39%\n",
            "Epoch [6/10], Train Loss: 1.1679\n",
            "Validation Loss: 1.1777, Accuracy: 65.50%\n",
            "Epoch [7/10], Train Loss: 1.0686\n",
            "Validation Loss: 1.1191, Accuracy: 67.46%\n",
            "Epoch [8/10], Train Loss: 0.9824\n",
            "Validation Loss: 1.0689, Accuracy: 69.85%\n",
            "Epoch [9/10], Train Loss: 0.9597\n",
            "Validation Loss: 1.0267, Accuracy: 69.99%\n",
            "Epoch [10/10], Train Loss: 0.8369\n",
            "Validation Loss: 0.9593, Accuracy: 71.67%\n",
            "\n",
            "Evaluation: DenseNet-121: \n",
            "\n",
            "Accuracy: 70.71%\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        Astrocitoma T1       0.52      0.94      0.67        36\n",
            "      Astrocitoma T1C+       0.48      0.64      0.55        47\n",
            "        Astrocitoma T2       0.62      0.37      0.46        35\n",
            "          Carcinoma T1       1.00      0.93      0.96        14\n",
            "        Carcinoma T1C+       1.00      0.91      0.95        23\n",
            "          Carcinoma T2       1.00      0.80      0.89        15\n",
            "         Ependimoma T1       0.86      0.67      0.75         9\n",
            "       Ependimoma T1C+       0.67      0.40      0.50        10\n",
            "         Ependimoma T2       0.40      0.17      0.24        12\n",
            "      Ganglioglioma T1       0.75      0.75      0.75         4\n",
            "    Ganglioglioma T1C+       1.00      0.50      0.67         4\n",
            "      Ganglioglioma T2       0.75      0.60      0.67         5\n",
            "          Germinoma T1       1.00      0.67      0.80         6\n",
            "        Germinoma T1C+       0.75      0.38      0.50         8\n",
            "          Germinoma T2       1.00      0.43      0.60         7\n",
            "       Glioblastoma T1       0.78      0.64      0.70        11\n",
            "     Glioblastoma T1C+       0.92      0.63      0.75        19\n",
            "       Glioblastoma T2       1.00      0.45      0.62        11\n",
            "          Granuloma T1       1.00      0.83      0.91         6\n",
            "        Granuloma T1C+       0.86      0.86      0.86         7\n",
            "          Granuloma T2       0.00      0.00      0.00         4\n",
            "     Meduloblastoma T1       0.83      1.00      0.91         5\n",
            "   Meduloblastoma T1C+       0.62      0.57      0.59        14\n",
            "     Meduloblastoma T2       0.75      0.33      0.46         9\n",
            "         Meningioma T1       0.77      0.73      0.75        55\n",
            "       Meningioma T1C+       0.80      0.69      0.74        74\n",
            "         Meningioma T2       0.58      0.74      0.65        47\n",
            "        Neurocitoma T1       0.89      0.92      0.91        26\n",
            "      Neurocitoma T1C+       0.81      0.96      0.88        45\n",
            "        Neurocitoma T2       0.55      0.76      0.64        21\n",
            "  Oligodendroglioma T1       0.92      0.67      0.77        18\n",
            "Oligodendroglioma T1C+       1.00      0.73      0.85        15\n",
            "  Oligodendroglioma T2       0.57      0.57      0.57        14\n",
            "           Papiloma T1       0.77      0.71      0.74        14\n",
            "         Papiloma T1C+       0.71      0.91      0.80        22\n",
            "           Papiloma T2       0.50      0.31      0.38        13\n",
            "         Schwannoma T1       0.69      0.73      0.71        30\n",
            "       Schwannoma T1C+       0.61      0.79      0.69        39\n",
            "         Schwannoma T2       0.39      0.64      0.48        25\n",
            "        Tuberculoma T1       0.60      0.50      0.55         6\n",
            "      Tuberculoma T1C+       0.64      0.41      0.50        17\n",
            "        Tuberculoma T2       0.29      0.29      0.29         7\n",
            "            _NORMAL T1       1.00      0.82      0.90        51\n",
            "            _NORMAL T2       0.78      0.84      0.81        55\n",
            "\n",
            "              accuracy                           0.71       915\n",
            "             macro avg       0.74      0.64      0.67       915\n",
            "          weighted avg       0.73      0.71      0.70       915\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTraining DenseNet-121: \")\n",
        "model_d121 = create_densenet_model('densenet121')\n",
        "model_d121, train_losses_d121, val_losses_d121, val_accuracies_d121 = train_model(model_d121, train_loader, val_loader, epochs=10)\n",
        "\n",
        "print(\"\\nEvaluation: DenseNet-121: \")\n",
        "evaluate_model(model_d121, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdoPXZiVEajQ"
      },
      "source": [
        "Model DenseNet-169 callings for training and testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJLxFYZrEkc4",
        "outputId": "fef01c78-e378-4aa4-e2fa-505d227a77aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training DenseNet-169: \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DenseNet169_Weights.IMAGENET1K_V1`. You can also use `weights=DenseNet169_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/densenet169-b2777c0a.pth\" to /root/.cache/torch/hub/checkpoints/densenet169-b2777c0a.pth\n",
            "100%|██████████| 54.7M/54.7M [00:01<00:00, 50.3MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 2.8248\n",
            "Validation Loss: 2.0818, Accuracy: 47.69%\n",
            "Epoch [2/10], Train Loss: 1.8783\n",
            "Validation Loss: 1.5171, Accuracy: 59.61%\n",
            "Epoch [3/10], Train Loss: 1.5055\n",
            "Validation Loss: 1.3142, Accuracy: 65.22%\n",
            "Epoch [4/10], Train Loss: 1.2340\n",
            "Validation Loss: 1.1745, Accuracy: 65.50%\n",
            "Epoch [5/10], Train Loss: 1.0993\n",
            "Validation Loss: 1.0193, Accuracy: 70.41%\n",
            "Epoch [6/10], Train Loss: 0.9948\n",
            "Validation Loss: 0.9598, Accuracy: 73.49%\n",
            "Epoch [7/10], Train Loss: 0.8350\n",
            "Validation Loss: 0.9713, Accuracy: 71.25%\n",
            "Epoch [8/10], Train Loss: 0.7705\n",
            "Validation Loss: 0.8829, Accuracy: 73.07%\n",
            "Epoch [9/10], Train Loss: 0.6911\n",
            "Validation Loss: 0.8752, Accuracy: 74.47%\n",
            "Epoch [10/10], Train Loss: 0.5895\n",
            "Validation Loss: 0.8253, Accuracy: 76.30%\n",
            "\n",
            "Evaluation: DenseNet-169: \n",
            "\n",
            "Accuracy: 77.49%\n",
            "                        precision    recall  f1-score   support\n",
            "\n",
            "        Astrocitoma T1       0.69      0.75      0.72        36\n",
            "      Astrocitoma T1C+       0.79      0.66      0.72        47\n",
            "        Astrocitoma T2       0.63      0.49      0.55        35\n",
            "          Carcinoma T1       1.00      0.93      0.96        14\n",
            "        Carcinoma T1C+       0.95      0.91      0.93        23\n",
            "          Carcinoma T2       0.80      0.80      0.80        15\n",
            "         Ependimoma T1       1.00      0.44      0.62         9\n",
            "       Ependimoma T1C+       0.50      0.40      0.44        10\n",
            "         Ependimoma T2       0.71      0.42      0.53        12\n",
            "      Ganglioglioma T1       1.00      0.50      0.67         4\n",
            "    Ganglioglioma T1C+       0.75      0.75      0.75         4\n",
            "      Ganglioglioma T2       0.50      0.60      0.55         5\n",
            "          Germinoma T1       0.83      0.83      0.83         6\n",
            "        Germinoma T1C+       0.56      0.62      0.59         8\n",
            "          Germinoma T2       0.50      0.71      0.59         7\n",
            "       Glioblastoma T1       1.00      0.64      0.78        11\n",
            "     Glioblastoma T1C+       0.82      0.74      0.78        19\n",
            "       Glioblastoma T2       0.70      0.64      0.67        11\n",
            "          Granuloma T1       0.71      0.83      0.77         6\n",
            "        Granuloma T1C+       0.88      1.00      0.93         7\n",
            "          Granuloma T2       1.00      0.25      0.40         4\n",
            "     Meduloblastoma T1       1.00      1.00      1.00         5\n",
            "   Meduloblastoma T1C+       0.79      0.79      0.79        14\n",
            "     Meduloblastoma T2       0.83      0.56      0.67         9\n",
            "         Meningioma T1       0.70      0.93      0.80        55\n",
            "       Meningioma T1C+       0.72      0.88      0.79        74\n",
            "         Meningioma T2       0.76      0.72      0.74        47\n",
            "        Neurocitoma T1       1.00      1.00      1.00        26\n",
            "      Neurocitoma T1C+       0.83      0.98      0.90        45\n",
            "        Neurocitoma T2       0.89      0.81      0.85        21\n",
            "  Oligodendroglioma T1       0.92      0.67      0.77        18\n",
            "Oligodendroglioma T1C+       0.93      0.87      0.90        15\n",
            "  Oligodendroglioma T2       0.89      0.57      0.70        14\n",
            "           Papiloma T1       0.91      0.71      0.80        14\n",
            "         Papiloma T1C+       0.95      0.95      0.95        22\n",
            "           Papiloma T2       1.00      0.46      0.63        13\n",
            "         Schwannoma T1       0.77      0.77      0.77        30\n",
            "       Schwannoma T1C+       0.83      0.74      0.78        39\n",
            "         Schwannoma T2       0.55      0.64      0.59        25\n",
            "        Tuberculoma T1       0.80      0.67      0.73         6\n",
            "      Tuberculoma T1C+       0.83      0.29      0.43        17\n",
            "        Tuberculoma T2       0.40      0.29      0.33         7\n",
            "            _NORMAL T1       0.91      0.98      0.94        51\n",
            "            _NORMAL T2       0.65      0.98      0.78        55\n",
            "\n",
            "              accuracy                           0.77       915\n",
            "             macro avg       0.80      0.71      0.73       915\n",
            "          weighted avg       0.79      0.77      0.77       915\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nTraining DenseNet-169: \")\n",
        "model_d169 = create_densenet_model('densenet169')\n",
        "model_d169, train_losses_d169, val_losses_d169, val_accuracies_d169 = train_model(model_d169, train_loader, val_loader, epochs=10)\n",
        "\n",
        "print(\"\\nEvaluation: DenseNet-169: \")\n",
        "evaluate_model(model_d169, test_loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving history"
      ],
      "metadata": {
        "id": "sgSXr6cyJVOo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save DenseNet-121\n",
        "torch.save({\n",
        "    'model_state_dict': model_d121.state_dict(),\n",
        "    'train_losses': train_losses_d121,\n",
        "    'val_losses': val_losses_d121,\n",
        "    'val_accuracies': val_accuracies_d121\n",
        "}, 'densenet121_results.pt')\n",
        "\n",
        "# Save DenseNet-169\n",
        "torch.save({\n",
        "    'model_state_dict': model_d169.state_dict(),\n",
        "    'train_losses': train_losses_d169,\n",
        "    'val_losses': val_losses_d169,\n",
        "    'val_accuracies': val_accuracies_d169\n",
        "}, 'densenet169_results.pt')"
      ],
      "metadata": {
        "id": "cli5SlHFJYDB",
        "outputId": "a2081409-329c-42a0-bec6-6e7954e0f895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-463f7aff3403>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Save DenseNet-121\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m torch.save({\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel_d121\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m'train_losses'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_losses_d121\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'val_losses'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval_losses_d121\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plots"
      ],
      "metadata": {
        "id": "2-ofajXJJR2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_results(train_losses, val_losses, val_accuracies):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    # Loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_losses, 'r-', label='Train Loss')\n",
        "    if val_losses:\n",
        "        plt.plot(epochs, val_losses, 'g-', label='Validation Loss')\n",
        "    plt.title('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    if val_accuracies:\n",
        "        plt.plot(epochs, val_accuracies, 'b-', label='Validation Accuracy')\n",
        "        plt.title('Validation Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy (%)')\n",
        "        plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "4NZp65fcJTjB"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(train_losses_d121, val_losses_d121, val_accuracies_d121)"
      ],
      "metadata": {
        "id": "GqK42BCjJb7c",
        "outputId": "90e8b640-db1e-43ad-e191-ba643ccce0c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_losses_d121' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-9ad4193eb763>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses_d121\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses_d121\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracies_d121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses_d121' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_results(train_losses_d169, val_losses_d169, val_accuracies_d169)"
      ],
      "metadata": {
        "id": "DxqbvQHeIxmK",
        "outputId": "c50964f2-443b-4e63-fde0-1293c8cb80dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'train_losses_d169' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-ba1515cc79b5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_losses_d169\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_losses_d169\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracies_d169\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_losses_d169' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJd+5BGM5XkKc0qYdpfdbv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}